
\subsection{Constructing ghost penalties}%
\label{sec:constructing_ghost_penalties}

We have the following assumptions for the ghost penalty.
\begin{enumerate}[label=\textbf{EP\arabic*}]
    \item \label{as:EP1} The ghost penalty $g_{h}( \cdot ,\cdot ) $ extends the $H^{2}$ norm such that
        \begin{equation}
    \| D^2v_{h} \|_{ \mathcal{T} _{h} }^{ 2 }  \lesssim \| D^2 v_{h} \|_{ \Omega  }^{  2} + \abs{ v_{h} } _{g_{h}}^2 \quad \forall v_{h} \in V_{h}
        \end{equation}
\item \label{as:EP2} For $v \in H^{s}( \Omega ) $ and $r = \mathrm{ min} (s,k+2) $, the semi-norm $\abs{ \cdot  }_{g_{h}} $ satisfies the following estimate,
    \begin{equation}
    \abs{ C _{h}^{e} v } _{g_{h}} \lesssim  h^{r-2} \| v \|_{ r,\Omega  }^{  }.
    \end{equation}
\end{enumerate}
The goal in this chapter is to engineer an ghost penalty which fulfills these assumptions.

Let us denote the generalization of the normal derivative,
\begin{equation}
\partial _{n}^{j} v = \sum_{\abs{ \alpha  } =j }^{k} \frac{D ^{\alpha }v( x) n^{\alpha }}{\alpha !}, \quad \abs{ \alpha  } = \sum_{i=0}^{d} \alpha_{i}.
\end{equation}
We denote the multi-index $\alpha  = ( \alpha _{1}, \ldots, \alpha _{d})  $ of order $\abs{ \alpha  } = \sum_{i}^{}  \alpha _{i} = k $   and the normal vectors $n^{\alpha } = n_{1}^{\alpha _{1}} \ldots n_{d}^{\alpha _{d}}$.
Recall the notation for the derivates $D^{\alpha } v$
\footnote{
Remark that the operator $D^{\alpha }$  is related to with the derivate operator $\partial ^{\alpha } $ introduced in \eqref{eq:der}. For instance, for $d=2$ we have $\alpha = ( \alpha _{1}, \alpha _{2}) $  such that $ D^{1} v =  \nabla v  = \left[ \partial ^{( 1,0 )} v,\partial ^{( 0,1 )}v
\right]^{T}$ and $   D^2 v  = \begin{bmatrix}
\partial ^{( 2,0 )} v &  \partial ^{( 1,1) }v \\
\partial ^{( 1,1 )} v &  \partial ^{( 0,2) }v
\end{bmatrix}
 $.
},
that is
\begin{equation}
D ^{0} v  = v, \quad   D ^{1}v  = \nabla v \text{ and }  D ^{2} v  = J(\nabla v) = \mathrm{Hess}(v).
\end{equation}
where $J$ is the Jacobian operator .

The following result is the backbone of the face-based ghost penalty.
\begin{lemma}
    \label{lemma:bi_local_facet_estimate}
    Let $T_{1},T_{2 } \in  \mathcal{T} _{h}$ be two elements sharing a common face $F$. Then for $v_{h} \in V_{h}$ with polynomial degree $k$  we have
    \begin{equation}
    \| v_{h} \|_{ T_{1} }^{  }  \lesssim \| v_{h} \|_{ T_{2} }^{  } + \sum_{0\le j\le k}  {h^{2j +1}}^{} ( \jump{ \partial _{n}^{j} v_{h} }, \jump{ \partial ^{j}_{n} v_{h} }    )_{F}
    \end{equation}

\end{lemma}
\begin{proof}
    See \cite[Lemma 2.19]{gurkan2019stabilized}.
\end{proof}

We will now introduce the so-called ghost penalty faces, that is, \[
\mathcal{F} ^{g}_{h} = \left\{ F\in \mathcal{F} _{h} : T^{+}\cap \Gamma \neq \emptyset  \vee T^{-}\cap \Gamma \neq \emptyset  \right\}.
\]
This set is simply all facets that belong to all elements of the active mesh $\mathcal{T} _{h}$  intersected with $\Gamma $, i.e., all triangles to the cut cells $\mathcal{T} _{\Gamma }$. For an illustration, see Figure \ref{fig:illustration_F_g}.

\begin{proposition}
    \label{prop:hessian_change}
    Let $v_{h} \in V_{h} $ and $F \in  \mathcal{F} _{h}$. Assume that $ v_{h} = v_{h} |_{F}$,  then the following identity holds.
    \begin{equation}
    \partial ^{j}_{n} (D^2v_{h}) = D^2 ( \partial ^{j}_{n} v_{h}), \quad  j=0,1,2.
    \end{equation}
\end{proposition}

\begin{proof}

        Recall that $\left[ D^2 v \right]_{i_{1},i_{2}} = \partial _{x_{i_{1}}x_{i_{2}}} v $ for $i_{1}, i_{2} \in \left\{ 1,\ldots,d \right\} $ for $d$ dimensions. The case $j=0$ is trivial. For the case $j=2$ we have,
        \begin{equation}
                \begin{split}
                \partial^{2} _{n} (\partial _{x_{i_{1}} x_{i_{2}}} v) & = n^{T}  D^2(\partial _{x_{i_{1}} x_{i_{2}}} v) n = n^{T}  J( \nabla (\partial _{x_{i_{1}} x_{i_{2}}}v) ) n \\
                & =  n^{T}  J(\partial _{x_{i_{1}} x_{i_{2}}}(\nabla v) ) n = \partial _{x_{i_{1}} x_{i_{2}}} n^{T} J(\nabla v) n
                \end{split}.
        \end{equation}
            Thus, taking account for all elements in the matrix we get $\partial^{2} _{n} (D^2v) = D^2( \partial^{2} _{n}v)$. The case $j=1$ is computed similarly.

\end{proof}

\begin{lemma}[]
    \label{lemma:bi_local_facet_estimate_2}
    Let $T_{1},T_{2 } \in  \mathcal{T} _{h}$ be two elements sharing a common face $F$. Then for $v_{h} \in V_{h}$ with polynomial degree $k$ we have
    \begin{subequations}
    \begin{align}
        \label{eq:local_ghost:0}
        \| \partial _{x_{i}} v \|_{ T_{1} }^{  }  &\lesssim \| \partial_{ x_{i} } v_{h} \|_{ T_{2} }^{  } + \sum_{0\le j\le k}  {h^{2j -1}}^{} ( \jump{ \partial _{n}^{j} \partial _{x_{i}} v_{h} }, \jump{ \partial ^{j}_{n} \partial _{x_{i}} v_{h} }
        )_{F} \\
        \label{eq:local_ghost:1}
        \| \nabla  v \|_{ T_{1} }^{  }  & \lesssim \| \nabla  v_{h} \|_{ T_{2} }^{  } + \sum_{0\le j\le k}  {h^{2j -1}}^{} ( \jump{ \partial _{n}^{j} \nabla v_{h} }, \jump{ \partial ^{j}_{n} \nabla  v_{h} }    )_{F}
    \end{align}
    \end{subequations}
    Similarly, this is generalized to
    \begin{subequations}
        \begin{align}
        \label{eq:local_ghost:2}
        \| \Delta   v \|_{ T_{1} }^{  }  & \lesssim \| \Delta  v_{h} \|_{ T_{2} }^{  } + \sum_{0\le j\le k}  {h^{2j -3}}^{} ( \jump{ \partial _{n}^{j}\Delta  v_{h} }, \jump{ \partial ^{j}_{n} \Delta   v_{h} }    )_{F} \\
        \label{eq:local_ghost:3}
        \| D^2  v \|_{ T_{1} }^{  }  & \lesssim \| D^2 v_{h} \|_{ T_{2} }^{  } + \sum_{0\le j\le k}  {h^{2j -3}}^{} ( \jump{ \partial _{n}^{j} D^2 v_{h} }, \jump{ \partial ^{j}_{n} D^2  v_{h} }    )_{F}
        \end{align}
    \end{subequations}

\end{lemma}

\begin{proof}
\textbf{Estimate \eqref{eq:local_ghost:0}.} Let $w_{h} = w_{h}|_F$ and recall the projection \eqref{eq:projection}, then is
\begin{equation}
    \begin{split}
\jump{ \partial _{x_{i}} w_{h}} & = \jump{ \nabla w_{h} }   \cdot e_{x_{i}}  = ( P_{F} \jump{ \nabla w_{h} }   + Q_{F}  \jump{ \nabla w_{h} }   )e_{x_{i}} \\
 &   = ( \jump{\partial _{n}    w_{h} }    n + \sum_{j=1}^{d-1}  \jump{\partial_{ t_{j} } w_{h} }    t_{j} )e_{x_{i}}
    \end{split}
\end{equation}
Here is $e_{x_{i}}, i= 1,\ldots,d$ one of the elementary unit vectors in $\mathbb{R} ^{d}$.
Since $\abs{e_{x_{i}} \cdot n  }\le 1 $ and $\abs{e_{x_{i}} \cdot  t_{j} }\le 1 \ \forall i,j $ is it clear that this estimate holds.

\begin{equation}
    \begin{split}
   \| \jump{ \partial _{x_{i}} w_{h} }   \|_{F  }^{2  } & \lesssim \| \jump{ \partial _{n} w_{h} }   \|_{F  }^{ 2 } + \sum_{j=1}^{d-1} \| \jump{ \partial _{t_{j}} w_{h} }   \|_{ F }^{ 2 } \\
    & \lesssim \| \jump{ \partial _{n} w_{h} }   \|_{F  }^{ 2 } +  h^{-2} \| \jump{ w_{h} }   \|_{ F }^{ 2 }
    \end{split}
\end{equation}
Here we used the local inverse inequality \eqref{eq:inv1} applied on the facet $F$, i.e. $\| \partial _{t_{j}} v_{h} \|_{F  }^{  } \lesssim h^{-1} \|  v_{h} \|_{F  }^{  }  $.
Inserting $w_{h} = \partial ^{j} _{n} v_{h}$ we conclude
\begin{equation}
    \label{eq:jump_estimate}
    \begin{split}
   \| \jump{ \partial _{x_{i}} \partial ^{j} _{n} v_{h} }   \|_{F  }^{2  } & \lesssim \| \jump{ \partial _{n} \partial ^{j} _{n} v_{h} }   \|_{F  }^{ 2 } +  h^{-2} \| \jump{ \partial ^{j} _{n} v_{h} }   \|_{ F }^{ 2 } \\
                                                                           & \lesssim \| \jump{  \partial ^{j+1} _{n} v_{h} }   \|_{F  }^{ 2 } +  h^{-2} \| \jump{ \partial ^{j} _{n} v_{h} }   \|_{ F }^{ 2 } \\
    \end{split}
\end{equation}
Next, we see that the Lemma \ref{lemma:bi_local_facet_estimate} implies
\begin{equation}
    \label{eq:ghost_estimate:1}
    \begin{split}
    \| \partial _{x_{i}} v_{h} \|_{  T_{1}}^{2  } & \lesssim \| \partial _{x_{i}} v_{h} \|_{ T_{2} }^{  2} + h^{2j+1}\sum_{j=0}^{k} \| \jump{ \partial _{n}^{j} \partial _{x_{i}} v_{h} }   \|_{F  }^{2  }.
    \end{split}
\end{equation}
Hence, by using \eqref{eq:jump_estimate} can we rewrite the sum such that
\begin{equation}
    \label{eq:ghost_estimate:2}
    \begin{split}
                                                  \sum_{j=0}^{k} \| \jump{ \partial _{n}^{j} \partial _{x_{i}} v_{h} }   \|_{F  }^{2  } & \lesssim  \sum_{j=0}^{k} \| \jump{  \partial ^{j+1} _{n} v_{h} }   \|_{F  }^{ 2 } +  h^{-2} \| \jump{ \partial ^{j} _{n} v_{h} }   \|_{ F }^{ 2 } \\
                                                  & \lesssim  \sum_{j=1}^{k-1} \| \jump{  \partial ^{j} _{n} v_{h} }   \|_{F  }^{ 2 } +\sum_{j=0}^{k}  h^{-2} \| \jump{ \partial ^{j} _{n} v_{h} }   \|_{ F
                                                  }^{ 2 } \\
                                                  & \lesssim  \sum_{j=0}^{k}  h^{-2} \| \jump{ \partial ^{j} _{n} v_{h} }   \|_{ F }^{ 2 }
    \end{split}
\end{equation}

Thus, combining \eqref{eq:ghost_estimate:1} and \eqref{eq:ghost_estimate:2} we get
\begin{equation}
    \| \partial _{x_{i}} v_{h} \|_{  T_{1}}^{2  }  \lesssim \| \partial _{x_{i}} v_{h} \|_{ T_{2} }^{  2} + h^{2j-1}\sum_{j=0}^{k} \| \jump{ \partial _{n}^{j} v_{h} }   \|_{F  }^{2  } \\
\end{equation}
        Hence, estimate \eqref{eq:local_ghost:0} holds.

        \textbf{Estimate \eqref{eq:local_ghost:1}.} Using that $\| \nabla  v \|_{T_{}  }^{ 2 } =  \sum_{i=1}^{d} \|  \partial _{x_{i}} v  \|_{T_{}  }^{ 2 }$, can we directly apply the estimate \eqref{eq:local_ghost:0} element-wise.
        \begin{equation}
            \begin{split}
\| \nabla v \|_{T_{1}  }^{2  } = \sum_{i=1}^{d} \| \partial _{x_{i}}  v_{h} \|_{ T_{1} }^{  2} & \lesssim  \sum_{i=1}^{d} \| \partial _{x_{i}}  v_{h} \|_{ T_{2} }^{  2} + h^{2j-1}\sum_{j=0}^{k} \| \jump{ \partial _{n}^{j} v_{h} }   \|_{F  }^{2  }  \\
         &  = \| \nabla  v_{h} \|_{ T_{2} }^{  2} + h^{2j-1}\sum_{j=0}^{k} \| \jump{ \partial _{n}^{j} v_{h} }   \|_{F  }^{2  }
            \end{split}
        \end{equation}
        Hence, estimate \eqref{eq:local_ghost:1} holds.


\textbf{Estimate \eqref{eq:local_ghost:2} and \eqref{eq:local_ghost:3}.}
Following exactly the same steps as in \textbf{Estimate \eqref{eq:local_ghost:0}}, but replacing Lemma \ref{lemma:bi_local_facet_estimate} with estimate \eqref{eq:local_ghost:0}, it is straight forward to conclude the following. For any  $i_{1},i_{2} \in
\left\{ 1,\ldots, d \right\}$ we have,
\begin{equation}
    \| \partial _{x_{i_1} x_{i_2}} v \|_{ T_{1} }^{  }  \lesssim \| \partial_{ x_{i_1} x_{i_2} } v_{h} \|_{ T_{2} }^{  } + \sum_{0\le j\le k}  {h^{2j -3}}^{} \left(  \jump{ \partial _{n}^{j} \partial _{x_{i_1} x_{i_2}} v_{h} }, \jump{ \partial ^{j}_{n}
        \partial _{x_{i_1} x_{i_2}} v_{h} } \right)     _{F}
\end{equation}
Finally, applying the element-wise argument, demonstrated in the proof for \textbf{Estimate \eqref{eq:local_ghost:1}}, for the Hessian and the Laplace operator, we conclude that \eqref{eq:local_ghost:2} and \eqref{eq:local_ghost:3} hold.

\end{proof}



\begin{figure}
    \centering
    \begin{tikzpicture}
        \coordinate (center) at (0, 0);

        % Reference hexagon vertices
        \coordinate (A1) at (0:2.5);
        \coordinate (A2) at (60:2.5);
        \coordinate (A3) at (120:2.5);
        \coordinate (A4) at (180:2.5);
        \coordinate (A5) at (240:2.5);
        \coordinate (A6) at (300:2.5);
        \coordinate (A7) at (300:2.5);


        \fill[green!40] (center) --(A1) -- (A2) -- (A3) -- (A4)  -- cycle;
        \fill[blue!30] (center) -- (A4) --(A5)--(A6)-- (A7) -- (A1) -- cycle;

        % Draw the individual edges
        \draw[dotted, line width=1.5pt] (center) -- (A1);
        \draw[dotted, line width=1.5pt] (center) -- (A2);
        \draw[dotted, line width=1.5pt] (center) -- (A3) -- (A4) -- (center);
        \draw (A2) -- (A3);
        \draw (A4) -- (A5);
        \draw (center) -- (A5) -- (A6) ;
        \draw (center) -- (A6) -- (A1);


        \begin{scope}[shift={(2.5,0)}]
            % Shifted
            \coordinate (center) at (0, 0);

            % Reference hexagon vertices
            \coordinate (B1) at (0:2.5);
            \coordinate (B2) at (60:2.5);
            \coordinate (B3) at (120:2.5);
            \coordinate (B5) at (240:2.5);
            \coordinate (B6) at (300:2.5);

            \fill[green!40] (center) --(B6) -- (B1) -- (B2) --(B3) -- cycle;
            \fill[blue!30] (center) -- (B5) --(B6) -- cycle;


            % Draw the individual edges
            \draw[dotted, line width=1.5pt] (center) -- (B2);
            \draw[dotted, line width=1.5pt] (center) -- (B3); % double
            \draw[dotted, line width=1.5pt] (center) -- (B1);
            \draw (B1) -- (B2);
            \draw (B2) -- (B3);
            \draw (B5) -- (B6);
            \draw[dotted, line width=1.5pt] (center) -- (B6) -- (B1);
        \end{scope}


        \coordinate (Ti) at (-0,-1.0);
        \coordinate (Tg) at (3.0,2.0);
        \node[below] at (Tg) {$\mathcal{T}^{\Gamma }_h$};
        \node[below] at (Ti) {$\mathcal{T}^{\mathrm{int} }_h$};

        \coordinate (C1) at (-3,0);
        \coordinate (C2) at (5.2,-0.5);
        \draw[-, line width=2pt, >=stealth] ($(C2)$) to[bend right] node[midway, yshift=-0.3cm] {$\Gamma $} ($(C1)$);

        \begin{scope}[shift={(6.0,1.7)}]
            \draw[dotted, line width=1.5pt] (-1.5,0) -- (-1,0);
            \node[anchor=west] at (-1.0,0) {$\mathcal{F}_h^g$};
        \end{scope}

        % Symbol visualization
        % \draw[dotted, line width=1.5pt] (3.4,3.1) -- (3.9,3.1);
        % \node[anchor=west] at (4.0,3.1) {$\mathcal{F}_h^g$};
        %% Legend
        \draw (4.4,1.3) rectangle (5.8,2.1); % Legend box

\end{tikzpicture}

\caption{Illustration of $\mathcal{F} _{h}^{g}$ denoted as the dotted lines. The set is defined as all facets which belongs to cut cells $\mathcal{T} ^{\Gamma }_{h}$ sharing a node with interior elements $\mathcal{T} ^{\mathrm{int}  }_{h}$ .  }
\label{fig:illustration_F_g}
\end{figure}


Now it remains to make this Lemma hold for the active mesh.


\begin{lemma}
    \label{lemma:bi_inv_gh_lemma}
    For $v_{h} \in  V_{h}$ of polynomial degree $k$, the following estimates hold.
        \begin{subequations}
            \begin{align}
                \label{eq:bi_inv_gh_1}
                \| v_h \|_{ \mathcal{T} _{h} }^{ 2 }  & \lesssim  \| v_h \|_{ \Omega  }^{ 2 }  + \sum_{j=1}^{k} h^{2j+1} ( \jump{ \partial ^{j}_{n} v }, \jump{ \partial ^{j}_{n} v_h}    )_{\mathcal{F}_{h}^{g}}\\
                \label{eq:bi_inv_gh_2}
                \| D ^2 v_h \|_{ \mathcal{T} _{h} }^{ 2 }  & \lesssim  \| D^2 v_h \|_{ \Omega  }^{ 2 }  + \sum_{j=1}^{k} h^{2j-3} ( \jump{ \partial ^{j}_{n} v_h }, \jump{ \partial ^{j}_{n}v_h }    )_{\mathcal{F}_{h}^{g}} \\
                \label{eq:bi_inv_gh_3}
                \| \Delta v_h \|_{ \mathcal{T} _{h} }^{ 2 }  & \lesssim  \| \Delta v_h \|_{ \Omega  }^{ 2 }  + \sum_{j=1}^{k} h^{2j-3} ( \jump{ \partial ^{j}_{n} v_h }, \jump{ \partial ^{j}_{n}v_h }    )_{\mathcal{F}_{h}^{g}}
            \end{align}
        \end{subequations}
\end{lemma}

\begin{proof}
        \textbf{Estimate \eqref{eq:bi_inv_gh_1}.}
        This estimate is proven in \cite[Lemma 2.20]{gurkan2019stabilized}, but we will include it for completeness.
            First of all, notice that there is a patch $P(T) $ consisting of $\left\{ T_{i} \right\}_{i=1}^{l} $ mesh elements such that each pair $ \left\{ T_{i}, T_{i+1} \right\} $ share a facet $F_{i}$ and the last element $T_{l}$ has a fat intersection.

            Let us define the following norm
            \begin{equation}
            g_{F_{i}}^{L^{2}}( v_{h},v_{h})  = \sum_{j=1}^{k} h^{2j+1}( \jump{ \partial ^{j}_{n}v_{h} }, \jump{ \partial ^{j}_{n}v_{h} }    )_{F_{i} }
            \end{equation}
            where $F_{i} \in  \mathcal{F} ^{g}_{h}$ and polynomial degree $ k$. Using Lemma \ref{lemma:bi_local_facet_estimate} can we see that
            \begin{equation}
            \| v_{h} \|_{ T_{i} }^{  } \lesssim \| v_{h} \|_{ T_{i+1} }^{ 2 } + g_{F_{i}}^{L^{2}}( v,v).
            \end{equation}
By employing induction on each pair $\left\{ T_{i}, T_{i+1} \right\}$ along with its corresponding $F_{i}$, we achieve the following outcome.

    \begin{align}
            \| v_{h} \|_{ T_{1} }^{2  }  & \le  C \| v_{h} \|_{ T_{2} }^{ 2 } + g_{F_{1}}^{L^{2}}( v_{h},v_{h})\\
              & \le  C( C( \| v_{h} \|_{ T_{3} }^{ 2 } + g_{F_{2}}^{L^{2}}( v_{h},v_{h}) ) + g_{F_{1}}^{L^{2}}( v_{h},v_{h}) )\\
              & \lesssim    \| v_{h} \|_{ T_{l} }^{ 2 }  + \sum_{i=1}^{l-1} g_{F_{i}}^{L^{2}}( v_{h},v_{h})  \\
              & \lesssim    \| v_{h} \|_{ T_{l} \cap \Omega  }^{ 2 }  + \sum_{i=1}^{l-1} g_{F_{i}}^{L^{2}}( v_{h},v_{h})
    \end{align}
            Here the last steps arise from the fact that $\|  v_{h} \|_{ T_{l} }^{  } \lesssim  \|  v_{h} \|_{ T_{l} \cap \Omega  }^{  }  $, which is a consequence of the fat intersection property.
            Summation over the cut elements $\mathcal{T} ^{\Gamma }_{h}$ implies,
            \begin{align}
                    \| v_{h} \|_{ \mathcal{T} ^{\Gamma }_h }^{2  } & \lesssim \| v_{h} \|_{ \mathcal{T} ^{\Gamma }_h\cap \Omega  }^{2  }+ \sum_{i=1}^{l-1} g_{F_{l}}^{L^{2}}( v_{h},v_{h}) \\
                                                                 & = \| v_{h} \|_{ \mathcal{T}^{\Gamma }_h \cap \Omega   }^{ 2 }  + \sum_{j=0}^{k} h^{2j+1} ( \jump{ \partial ^{j}_{n} v_{h} }, \jump{ \partial ^{j}_{n}v_{h} }    )_{\mathcal{F}_{h}^{g}}
            \end{align}
        And as a trivial extension this now also holds for the active mesh $\mathcal{T} _{h}$ , that is,
        \begin{equation}
                    \| v_{h} \|_{ \mathcal{T} _{h } }^{2  } \lesssim  \| v_{h} \|_{ \mathcal{T}_{h } \cap \Omega   }^{ 2 }  + \sum_{j=1}^{k} h^{2j+1} ( \jump{ \partial ^{j}_{n} v_{h} }, \jump{ \partial ^{j}_{n}v_{h} }    )_{\mathcal{F}_{h}^{g}}.
        \end{equation}
        Hence, \eqref{eq:bi_inv_gh_1} holds and the first part of the proof is complete.

        \textbf{Estimate \eqref{eq:bi_inv_gh_2} and \eqref{eq:bi_inv_gh_2}.}
        We will simply use the exact same procedure as \textbf{Estimate \eqref{eq:bi_inv_gh_1}}  for the estimates with \eqref{eq:local_ghost:2}  and \eqref{eq:local_ghost:3}. Hence, proof is complete.
    \end{proof}

Finally, we now have the tools we need to construct an candidate for the ghost penalty for which satisfies all assumptions.

\begin{proposition}[Face-based ghost penalty]
    Let $k\ge  2$ be the order of the polynomial basis in $V_{h}$ .
    For any set of positive parameters $\left\{ \gamma _{j} \right\} _{j=0}^{k}$, the ghost penalty defined as
    \begin{equation}
        \label{eq:ghost_penalty}
    g^{}_{h}( v_{h},w_{h})  := \sum_{j=1}^{k} \sum_{F \in \mathcal{F} _{h}^{g}}^{} \gamma _{j} h^{2j-3}_{F} ( \jump{ \partial ^{j}_{n} v_{h} }, \jump{ \partial ^{j}_{n} w_{h} }  ) _{F} \text{ for any } v_{h},w_{h} \in V_{h},
    \end{equation}
    satisfies the Assumption \ref{as:EP1} and \ref{as:EP2}.
\end{proposition}

\begin{proof}
  From Lemma \ref{lemma:bi_inv_gh_lemma} is it clear that $
    \| D^2v_{h} \|_{ \mathcal{T} _{h} }^{  }  \lesssim \| D^2 v_{h} \|_{ \Omega   }^{  } + \abs{ v_{h} } _{g_{h}}
    $, hence, Assumption \ref{as:EP1} holds.
    Therefore, we only need to verify Assumption \ref{as:EP2}, which states that $ \abs{ C^{e}_{h} v }_{g_{h}} \lesssim h^{r-2} \| v \|_{r, \Omega   }^{  }$.
    Let $v  \in H^{s}( \Omega ) $, $s\ge 3$,  and $r = \min\{s,k+1\} $. We can see that from definition is,
    \begin{equation}
        \label{eq:est_gh:1}
        \begin{split}
        \abs{ C^{e}_{h} v }_{g_{h}}^{2} & = \sum_{j=0}^{k}  \gamma _{j} h^{2j-3}  \| \jump{ \partial ^{j}_{n} C^{e}_{h} v }  \|_{\mathcal{F}_{h}^{g} }^{2} \\
                                        & = \sum_{j=0}^{r-1}  \gamma _{j} h^{2j-3}   \| \jump{ \partial ^{j}_{n}  C^{e}_{h} v  }  \|_{\mathcal{F}_{h}^{g} }^{2} + \sum_{j=r}^{k}  \gamma _{j} h^{2j-3}  \| \jump{ \partial ^{j}_{n} C^{e}_{h} v }
                                        \|_{\mathcal{F}_{h}^{g} }^{2} = \mathrm{I} + \mathrm{II}
        \end{split}
    \end{equation}
Here we added a zero term $v^{e} \in H^{s}( \Omega_{h} ) $  since jump vanishes for the for the first $r-1$ terms, i.e. $\jump{ \partial ^{j}_{n} v^{e} } = 0  \  \forall s \le r-1$.
    \begin{enumerate}[label=\arabic*)]
        \item \textbf{Version 1.}
    \begin{equation}
        \begin{split}
       \sum_{j=0}^{k}  \gamma _{j} h^{2j-3}  \| \jump{ \partial ^{j}_{n} C^{e}_{h} v }  \|_{\mathcal{F}_{h}^{g} }^{2} & \lesssim \sum_{j=0}^{k} h^{2j-3}  \|  \partial ^{j}_{n} C^{e}_{h} v \|_{\partial \mathcal{T}_{h} }^{2} \lesssim \sum_{j=0}^{k} h^{2j-3} h^{2( r - j ) - 1}  \|  C^{e}_{h} v \|_{ r,\Omega  }^{2}  \\
       &  \lesssim h^{2( r-2) } \| C^{e}_{h}v \|_{r,\Omega}^{2}
        \end{split}
    \end{equation}

        \item \textbf{Version 2a of I.}
    What we can see is that the first term can easily be estimated using the a priori estimate \eqref{eq:bi_projection_estimates_2} ,
    \begin{equation}
        \begin{split}
        \mathrm{I}  & \lesssim \sum_{j=0}^{r-1} h^{2j-3}   \| \jump{ \partial ^{j}_{n}  ( C^{e}_{h} v - v^{e})   }  \|_{\mathcal{F}_{h}^{g} }^{2} \\
        & \lesssim \sum_{j=0}^{r-1} h^{2j-3}  h^{2r - j - 1}\| v  \|_{r,\Omega  }^{2} \\
        & \lesssim \sum_{j=0}^{r-1}  h^{2r + j - 4}\| v  \|_{r,\Omega  }^{2} \lesssim   h^{3r - 5}\| v  \|_{r,\Omega  }^{2}
        \end{split}
    \end{equation}
\red{Not sure if this estimate makes sense since we must extend to the full space $\partial \mathcal{T} _{h}$, see \eqref{eq:mean_jump_estimate} }
\item
    \textbf{Version 2b of I.} Using the trace inequality \eqref{eq:trace:1}, i.e.
    \begin{equation}
\|  D^{j} v     \|_{ \partial T }^{2} \lesssim h^{-\frac{1}{2}}\|  D ^{j} v     \|_{  T }^{2} + h^{\frac{1}{2}}\|  D ^{j+1} v     \|_{  T }^{2}, \quad v \in H^{j+1}( T )
    \end{equation}
    such that
    \begin{equation}
        \begin{split}
        \mathrm{I}  & \lesssim \sum_{j=0}^{r-1} h^{2j-3}   \|  D ^{j}  ( C^{e}_{h} v - v^{e})     \|_{ \partial \mathcal{T}_{h} }^{2} \\
                    & \lesssim \sum_{j=0}^{r-1} h^{2j-3}   (h^{-1} \|  D ^{j} ( C^{e}_{h} v - v^{e})     \|_{  \mathcal{T}_{h} }^{2} + h \|  D ^{j+1} ( C^{e}_{h} v - v^{e})     \|_{  \mathcal{T}_{h}  }^{2} )   \\
                    & \lesssim \sum_{j=0}^{r-1} h^{2j-3}   ( h^{2( r-j) -2 } +  h^{2( r-j+1) }  )\| v \|_{r,\Omega   }^{2  } \\
                    & \lesssim \sum_{j=0}^{r-1}    ( h^{2 r -5 } +  h^{2r-1 }  )\| v \|_{r,\Omega   }^{2  }
        \end{split}
    \end{equation}
    Here we applied \eqref{eq:bi_projection_estimates_1}.

    \end{enumerate}



     For the second term are we allowed to use the basic inverse
    estimate \eqref{eq:general} on the Cl√©ment operator,
    \begin{equation}
        \begin{split}
       \mathrm{II}  & \lesssim \sum_{j=r}^{k} h^{2j-3}  \|  \partial ^{j}_{n} C^{e}_{h} v \|_{\partial \mathcal{T}_{h} }^{2} \lesssim \sum_{j=r}^{k} h^{2j-3} h^{2( r - j ) - 1}  \|  C^{e}_{h} v \|_{ r,\Omega  }^{2}  \\
       &  \lesssim h^{2( r-2) } \| C^{e}_{h}v \|_{r,\Omega}^{2}
        \end{split}
    \end{equation}
    Hence, the estimate $\abs{ C^{e}_{h} v }_{g_{h}}^{2} \lesssim h^{2( r -2 )}\| v \|_{r, \Omega   }^{2}$ holds.

\end{proof}
